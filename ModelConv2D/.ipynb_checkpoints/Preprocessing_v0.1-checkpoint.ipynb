{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c80ea-7cf0-4a17-a10b-6d48c35e459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331b22a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O caminho existe e está acessível.\n",
      "A iterar C:/Dev/DatasetMEIA/train\\Atopic Dermatitis Photos\n",
      "A iterar C:/Dev/DatasetMEIA/train\\Lupus and other Connective Tissue diseases\n",
      "A iterar C:/Dev/DatasetMEIA/train\\Melanoma Skin Cancer Nevi and Moles\n",
      "A iterar C:/Dev/DatasetMEIA/train\\Psoriasis pictures Lichen Planus and related diseases\n",
      "A iterar C:/Dev/DatasetMEIA/train\\Urticaria Hives\n",
      "Fim do carregamento de imagens\n",
      "A iterar C:/Dev/DatasetMEIA/test\\Atopic Dermatitis Photos\n",
      "A iterar C:/Dev/DatasetMEIA/test\\Lupus and other Connective Tissue diseases\n",
      "A iterar C:/Dev/DatasetMEIA/test\\Melanoma Skin Cancer Nevi and Moles\n",
      "A iterar C:/Dev/DatasetMEIA/test\\Psoriasis pictures Lichen Planus and related diseases\n",
      "A iterar C:/Dev/DatasetMEIA/test\\Urticaria Hives\n",
      "Fim do carregamento de imagens\n",
      "Número de imagens de treino carregadas: 2989\n",
      "Número de imagens de teste carregadas: 749\n"
     ]
    }
   ],
   "source": [
    "# Função para carregar imagens de uma pasta\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    #Considera todas as pastas dentro do diretorio que se encontra\n",
    "    disease_folder=glob.glob(os.path.join(folder, \"*\"))\n",
    "    for files in disease_folder:\n",
    "        print(f\"A iterar {files}\")\n",
    "        for filename in os.listdir(files):\n",
    "            try:\n",
    "                img = cv2.imread(os.path.join(files, filename))\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                else:\n",
    "                    print(f\"Não foi possível carregar a imagem: {filename}\")\n",
    "            except Exception as e:\n",
    "                    print(f\"Erro ao carregar a imagem {img_path}: {str(e)}\")\n",
    "    print(\"Fim do carregamento de imagens\")            \n",
    "    return images\n",
    "\n",
    "# Diretório onde estão as imagens\n",
    "#train_folder = '/Users/hugopereira/DatasetMEIA/train'\n",
    "#test_folder = '/Users/hugopereira/DatasetMEIA/test'\n",
    "train_folder = 'C:/Dev/DatasetMEIA/train'\n",
    "test_folder = 'C:/Dev/DatasetMEIA/test'\n",
    "if os.path.exists(train_folder):\n",
    "    print(\"O caminho existe e está acessível.\")\n",
    "else:\n",
    "    print(\"O caminho não existe ou não está acessível.\")\n",
    "\n",
    "# Carregar imagens de treino e teste\n",
    "train_images = load_images_from_folder(train_folder)\n",
    "test_images = load_images_from_folder(test_folder)\n",
    "\n",
    "# Verificar se as imagens foram carregadas corretamente\n",
    "print(f\"Número de imagens de treino carregadas: {len(train_images)}\")\n",
    "print(f\"Número de imagens de teste carregadas: {len(test_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9654bc13-6255-400b-91c7-bce9c54313a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens de treino redimensionadas: 2989\n",
      "Número de imagens de teste redimensionadas: 749\n",
      "Número de imagens de treino arrays numpy: 2989\n",
      "Número de imagens de teste arrays numpy: 749\n"
     ]
    }
   ],
   "source": [
    "# Redimensionar imagens\n",
    "def resize_images(images, new_size):\n",
    "    resized_images = []\n",
    "    for img in images:\n",
    "        resized_img = cv2.resize(img, new_size)\n",
    "        resized_images.append(resized_img)\n",
    "    return resized_images\n",
    "\n",
    "# Tamanho desejado para as imagens (224x224)\n",
    "new_size = (224, 224)\n",
    "\n",
    "# Redimensionar imagens de treino e teste\n",
    "train_images_resized = resize_images(train_images, new_size)\n",
    "test_images_resized = resize_images(test_images, new_size)\n",
    "\n",
    "# Verificar se as imagens foram redimensionadas corretamente\n",
    "print(f\"Número de imagens de treino redimensionadas: {len(train_images_resized)}\")\n",
    "print(f\"Número de imagens de teste redimensionadas: {len(test_images_resized)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b10bb6a-b76e-48ce-8956-804574a286f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de imagens de treino redimensionadas: 2989\n",
      "Número de imagens de teste redimensionadas: 749\n",
      "Número de imagens de treino arrays numpy: 2989\n",
      "Número de imagens de teste arrays numpy: 749\n"
     ]
    }
   ],
   "source": [
    "# Converter listas de imagens para arrays numpy\n",
    "train_images_array = np.array(train_images_resized)\n",
    "test_images_array = np.array(test_images_resized)\n",
    "\n",
    "# Verificar se as imagens foram convertidas corretamente para arrays numpy\n",
    "print(f\"Número de imagens de treino arrays numpy: {len(train_images_array)}\")\n",
    "print(f\"Número de imagens de teste arrays numpy: {len(test_images_array)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58d5d4a6-6a4f-499a-93d9-7d75a5bffa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagens duplicadas encontradas:\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "#Verificar se existe imagens duplicadas\n",
    "duplicates=np.intersect1d(train_images_array, test_images_array)\n",
    "\n",
    "if len(duplicates)>0: \n",
    "    print(\"Imagens duplicadas encontradas:\")\n",
    "    for duplicate in duplicates:\n",
    "        print(duplicate)\n",
    "else:\n",
    "    print(\"Não foram encontradas imagens duplicadas.\")\n",
    "\n",
    "def verify_duplicate(imagens_np):\n",
    "    duplicate=[]\n",
    "    for i in range(len(imagens_np)):\n",
    "        for j in range(i+1, len(imagens_np)):\n",
    "            if np.array_equal(imagens_np[i], imagens_np[j]):\n",
    "                duplicate.append((i, j))\n",
    "    return duplicate\n",
    "\n",
    "duplicates_train=verify_duplicate(train_images_array)\n",
    "duplicates_test=verify_duplicate(test_images_array)\n",
    "\n",
    "if len(duplicates_train)>0: \n",
    "    print(\"Imagens duplicadas encontradas no conjunto treino:\")\n",
    "    for duplicate in duplicates:\n",
    "        print(duplicate)\n",
    "else:\n",
    "    print(\"Não foram encontradas imagens duplicadas no conjunto treino.\")\n",
    "\n",
    "if len(duplicates_test)>0: \n",
    "    print(\"Imagens duplicadas encontradas no conjunto teste:\")\n",
    "    for duplicate in duplicates:\n",
    "        print(duplicate)\n",
    "else:\n",
    "    print(\"Não foram encontradas imagens duplicadas no conjunto teste:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b740c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do array de imagens de treino: (2989, 224, 224, 3)\n",
      "Shape do array de imagens de teste: (749, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Verificar as formas dos arrays de imagens\n",
    "print(f\"Shape do array de imagens de treino: {train_images_array.shape}\")\n",
    "print(f\"Shape do array de imagens de teste: {test_images_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481623d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização\n",
    "def normalize_images(images):\n",
    "    normalized_images = []\n",
    "    for img in images:\n",
    "        normalized_img = img / 255.0  # Normalizar os valores dos pixels para o intervalo [0, 1]\n",
    "        normalized_images.append(normalized_img)\n",
    "    return np.array(normalized_images)\n",
    "\n",
    "# Normalizar imagens de treinamento e teste\n",
    "train_images_normalized = normalize_images(train_images_resized)\n",
    "test_images_normalized = normalize_images(test_images_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab40c7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Criar um gerador de imagens com técnicas de aumento de dados\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "# Redimensionar imagens para o formato esperado pelo ImageDataGenerator\n",
    "train_images_normalized_resized = train_images_normalized.reshape(-1, new_size[0], new_size[1], 3)\n",
    "\n",
    "# Ajustar o gerador às imagens de treinamento\n",
    "datagen.fit(train_images_normalized_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd58af2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Redimensionar as imagens para o formato esperado pelo RandomOverSampler\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_images_flattened \u001b[38;5;241m=\u001b[39m train_images_normalized\u001b[38;5;241m.\u001b[39mreshape(train_images_normalized\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Aplicar oversampling\u001b[39;00m\n\u001b[1;32m      9\u001b[0m oversampler \u001b[38;5;241m=\u001b[39m RandomOverSampler()\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0,newaxis)"
     ]
    }
   ],
   "source": [
    "# Balanceamento de classes\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Redimensionar as imagens para o formato esperado pelo RandomOverSampler\n",
    "train_images_flattened = train_images_normalized.reshape(train_images_normalized.shape[0], -1)\n",
    "\n",
    "# Aplicar oversampling\n",
    "oversampler = RandomOverSampler()\n",
    "train_images_balanced, train_labels_balanced = oversampler.fit_resample(train_images_flattened, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09eac87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar o data-set pre-processado\n",
    "\n",
    "# Guardar imagens pré-processadas e rótulos em arquivos NumPy\n",
    "np.save('train_images.npy', train_images_balanced)\n",
    "np.save('train_labels.npy', train_labels_balanced)\n",
    "np.save('test_images.npy', test_images_normalized)\n",
    "np.save('test_labels.npy', test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
